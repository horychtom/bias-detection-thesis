\chapter{Conclusion}
In this work I collected and analyzed all the literature and resource for studying state-of-the-art media bias detection and performed a minor experiment focused on gender bias detection as well. I presented new czech parallel dataset derived from Wikipedia and, in addition, 9 parallel translated czech datasets for tackling the media bias detection in \textbf{Czech language}, one of them large scale (360k sentences).

I trained and tuned the BERT-based czech language model and achieved an F1 score of 80.4 \% on a small test subset of a target dataset. I performed experiments on combining different datasets for pre-training the model, to push the performance on validation set. Pre-training on Subjectivity detection datasets performed the best, however, all tuning performed has had generally very low effect on performance +0.7\%. 

Finally, the final classifier has been used to build a publicly available demo and to analyze a sample of articles from "INSERT SOURCE" throughout the 2002 - 2018 period of time. Results of this study showed a trend in progression of media bias in time and suggested/revelaed a positive correlation between bias of the headline and the average bias of the article.



\section{Future perspective}
As outlined in the introduction media bias seems to be a combination of several potentially independent tasks such as sentiment, agression or subjective analysis. In this thesis this hypothesis has been also somewhat supported by the result that pre-training on subjectivity task had the best influence on detection of \gls{mb} but a single-task model for subjectivity detection eventually performed worse than others. Therefore, as Spinde et. al \cite{spindeexploiting} suggest, multi-task approach could be used to enhance the classification ability of the current czech classifier.

Yet, the current czech classifier relies heavily on translated datasets, therefore I suggest that for the future improvement a construction of an original gold-standard czech dataset is essential.
