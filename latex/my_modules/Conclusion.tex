\chapter{Conclusion}
In this work, I collected and analyzed the literature and resources to study state-of-the-art media bias detection and also performed a minor experiment focused on gender bias detection. I presented a new Czech parallel dataset derived from Wikipedia with 5765 sentences and, in addition, nine parallel translated Czech datasets to tackle the detection of media bias in Czech language, one of them large-scale (WNC with 360k sentences).

I trained and tuned the BERT-based FERNET-C5 language model for binary classification and achieved an F1 score of 0.804 on a small test subset of the BABE media bias dataset. I performed experiments on combining different datasets for pre-training the model to push the performance on the validation set. The pre-training on all datasets combined performed the best; however, both hyperparameter tuning and pre-training had generally a very low effect on performance, approximately +0.7\% gain over the baseline. 

Finally, the final classifier has been used to build a publicly available demo and to analyze a sample of articles from "INSERT SOURCE" throughout the 2002 - 2018 period of time. The results of this study showed a trend in the progression of media bias over time and revealed a positive correlation between the headline bias and the average bias of the article.

\section{Ethical Concerns}
Although the performance of the current classifier is quite appealing, a standalone F1 score might not provide the appropriate evaluation of the model's ability. Perhaps a human evaluation should also play a role in the process.

Also, the model's decisions are not easily clarifiable. The problem with explainibility of the model is especially important when such classifier is brought to real-world applications. 


\section{Future perspective}
As outlined in the introduction (\ref{mb_intro}), according to allsides.com, media bias appears to be a combination of several potentially independent features, such as sentiment, agression, or subjectivity. In this thesis, this hypothesis has also been somewhat supported by the result that pre-training on subjectivity task had the best influence on detection of \gls{mb} but a single-task model for subjectivity detection eventually performed worse than others. Therefore, as Spinde et al. \cite{spindeexploiting} suggest, the multi-task approach could be used to improve the classification ability of the current Czech classifier.


Nevertheless, the current Czech classifier relies heavily on translated datasets; therefore, I suggest that, for future improvement, a construction of an original gold-standard Czech dataset is essential.
