{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ecd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making imports convenient\n",
    "import sys\n",
    "import os\n",
    "PATH=os.getcwd().split('/notebooks')[0]\n",
    "sys.path.insert(1,PATH)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_metric,load_dataset,Dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding,RobertaForSequenceClassification,AdamW,get_scheduler,TrainingArguments,Trainer\n",
    "\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import csv\n",
    "import gc\n",
    "\n",
    "from src.utils.myutils import clean_memory,compute_metrics,preprocess_data\n",
    "\n",
    "model_checkpoint = 'roberta-base'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3d363-87e8-4793-b753-2b516be15bde",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8bb581-daf7-4a7b-9307-fd2ca1ec7448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9aed32b2774fea6c\n",
      "Reusing dataset csv (/home/horyctom/.cache/huggingface/datasets/csv/default-9aed32b2774fea6c/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('csv',data_files=PATH+\"/data/EN/processed/BABE/babe_sg2.csv\")['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23619da5-0547-460a-a81e-c79431289cc4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21e99242-8bec-4015-bad1-5b925931277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a55195a5-5837-4dff-a84d-dfe2afcfc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint);\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_checkpoint);\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7e2fd6d-7277-4487-a172-2f4f753365fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=50,  \n",
    "    logging_steps=50,\n",
    "    disable_tqdm = False,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c8bde9a-3447-4f0b-b331-73ff4c170a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d888920a-2ca9-4085-a943-e22f39860ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/horyctom/.cache/huggingface/datasets/csv/default-57fcf4cd5490a3c0/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-addea159e382c769.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = preprocess_data(data,tokenizer,'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b75f54-b906-44cb-9c52-ff713ff1d9bf",
   "metadata": {},
   "source": [
    "### 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11d5d4e1-47e7-4431-89a9-ed37645b51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398fe99-daa1-49fa-acca-ecf7aa3f24db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for train_index, val_index in skfold.split(data['text'],data['label']):\n",
    "    \n",
    "    token_train = Dataset.from_dict(tokenized_data[train_index])\n",
    "    token_valid = Dataset.from_dict(tokenized_data[val_index])\n",
    "    \n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_checkpoint);\n",
    "    trainer = Trainer(model,training_args,train_dataset=token_train,data_collator=data_collator,\n",
    "                      tokenizer=tokenizer)\n",
    "    trainer.train()\n",
    "    \n",
    "    #evaluation\n",
    "    eval_dataloader = DataLoader(token_valid, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "    f1_scores.append(compute_metrics(model,device,eval_dataloader)['f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "220ab629-9d51-46ee-b8f7-a96dcc5c9226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8204081632653062,\n",
       " 0.8394557823129252,\n",
       " 0.8326530612244899,\n",
       " 0.8024523160762943,\n",
       " 0.8147138964577657]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17a7d8-b8e7-45fc-aa8e-011d5c805e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inferrence experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34fa0261-668f-48f9-a589-872ec3656020",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.'\n",
    "#sentence = 'This might be biased but mustache suits you.'\n",
    "toksentence = tokenizer(sentence,truncation=True,return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    toksentence.to(device)\n",
    "    output = model(**toksentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b07288b-2db1-48fa-9811-0a5cf11ddb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change. :  unbiased\n"
     ]
    }
   ],
   "source": [
    "classification = F.softmax(output.logits,dim=1).argmax(dim=1)\n",
    "print(sentence,': ',{0:'unbiased',1:'biased'}[classification[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301fe66-4a14-4be7-bf21-06dfefe415c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
