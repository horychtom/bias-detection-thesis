{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e9aa72a-a06b-4dfc-bb24-ddb1a079bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making imports convenient\n",
    "import sys\n",
    "import os\n",
    "PATH=os.getcwd().split('/notebooks')[0]\n",
    "sys.path.insert(1,PATH)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_metric,load_dataset,Dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding,RobertaForSequenceClassification,AdamW,get_scheduler,TrainingArguments,Trainer\n",
    "\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import csv\n",
    "import gc\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from src.utils.myutils import clean_memory,compute_metrics,preprocess_data\n",
    "\n",
    "model_name = 'roberta-base'\n",
    "\n",
    "logging.disable(logging.ERROR)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee64c787-7d34-4f95-a71d-db40c16a441e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3122\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 551\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('csv',data_files=PATH+\"/data/EN/processed/BABE/babe_sg2.csv\")['train']\n",
    "data = data.train_test_split(0.15,seed=42)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc29521-65bd-4919-ac18-d36dd1f4ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_eval(eval_preds):\n",
    "    metric = load_metric(\"f1\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(average='macro',predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "205ff6da-5110-443f-bb08-a39086729c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data['train']\n",
    "data_test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f84e7c-8521-45b2-9ff6-4ac931d35a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2e5050-0807-4c08-aeb6-5046ec40d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=BATCH_SIZE,  \n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_steps=2000,\n",
    "    logging_steps=2000,\n",
    "    save_steps=2000,\n",
    "    disable_tqdm = False,\n",
    "    warmup_steps=0,\n",
    "    save_total_limit=5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'f1',\n",
    "    weight_decay=0.2,\n",
    "    output_dir = './',\n",
    "    learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72322195-6731-4798-94f3-f1d07d4d6ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b816293a6385460a91ae087f822e299a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/327 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964113f263e94927832d22b31d2c1749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10210' max='10210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10210/10210 39:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.566780</td>\n",
       "      <td>0.693577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>0.560621</td>\n",
       "      <td>0.696465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.562900</td>\n",
       "      <td>0.549666</td>\n",
       "      <td>0.707594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>0.543451</td>\n",
       "      <td>0.711340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.551700</td>\n",
       "      <td>0.542310</td>\n",
       "      <td>0.713062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prep data\n",
    "data_wnc = load_dataset('csv',data_files = '/home/horyctom/bias-detection-thesis/data/EN/processed/WNC/wnc.csv')['train']\n",
    "data_wnc = data_wnc.train_test_split(0.1)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False,padding=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train = preprocess_data(data_wnc['train'],tokenizer,'sentence')\n",
    "test = preprocess_data(data_wnc['test'],tokenizer,'sentence')\n",
    "\n",
    "#Train\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name,num_labels=2);\n",
    "model.to(device)\n",
    "trainer = Trainer(model,training_args,train_dataset=train,data_collator=data_collator,tokenizer=tokenizer,eval_dataset=test,\n",
    "                          compute_metrics=compute_metrics_eval)\n",
    "\n",
    "trainer.train()\n",
    "torch.save(model.state_dict(),'/home/horyctom/bias-detection-thesis/src/models/trained/wncen_pretrained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f00b3e98-5a5d-4a6a-9ec3-1fa8fbc66306",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name);\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name);\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "298b92f5-bb1b-44b1-8611-9bc931a64139",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06640fd2-5dcc-4d29-893f-69f5be5a4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=0,  \n",
    "    logging_steps=50,\n",
    "    disable_tqdm = False,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb5f6f0c-4335-4156-868d-a91b26cc4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = preprocess_data(data_train,tokenizer,'text')\n",
    "tokenized_test = preprocess_data(data_test,tokenizer,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74a3715f-b664-41ab-98b8-8b2f8239fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "np.random.seed(2018)\n",
    "torch.manual_seed(2018)   \n",
    "random.seed(2018)    \n",
    "torch.cuda.manual_seed_all(2018)\n",
    "random.seed(2018)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af0f6171-de75-46fc-b2f6-da3c0780e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a522241a-fbe9-4646-9936-61605dff4cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.272000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.287800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.284500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.291700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.267400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_index, val_index in skfold.split(data_train['text'],data_train['label']):\n",
    "    \n",
    "    token_train = Dataset.from_dict(tokenized_train[train_index])\n",
    "    token_valid = Dataset.from_dict(tokenized_train[val_index])\n",
    "    \n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_checkpoint);\n",
    "    model.load_state_dict(torch.load('/home/horyctom/bias-detection-thesis/src/models/trained/wncen_pretrained.pth'))\n",
    "\n",
    "    trainer = Trainer(model,training_args,train_dataset=token_train,data_collator=data_collator,\n",
    "                      tokenizer=tokenizer)\n",
    "    trainer.train()\n",
    "    \n",
    "    #evaluation\n",
    "    eval_dataloader = DataLoader(token_valid, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "    f1_scores.append(compute_metrics(model,device,eval_dataloader)['f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844b907-5594-42b1-a037-9e537cc2db96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
