{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c7597ba-0267-4b4a-adaa-d68efd68a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making imports convenient\n",
    "import sys\n",
    "import os\n",
    "PATH=os.getcwd().split('/notebooks')[0]\n",
    "sys.path.insert(1, PATH)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "import transformers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding,AutoModelForSequenceClassification,TrainingArguments,Trainer\n",
    "\n",
    "from src.utils.myutils import *\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "logging.disable(logging.ERROR)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "CS_DATA_PATH = PATH + '/data/CS/processed/'\n",
    "CONFIG_PATH = PATH + '/src/utils/config.yaml'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = 'fav-kky/FERNET-C5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False,padding=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a0d3aa-0513-4969-9704-1d65a0a5510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "babe = load_dataset('csv',data_files=CS_DATA_PATH+'BABE/train.csv')['train']\n",
    "\n",
    "cw_hard = load_dataset('csv',data_files = CS_DATA_PATH + 'CW-HARD/cw-hard.csv')['train']\n",
    "cwnc = load_dataset('csv',data_files = CS_DATA_PATH + 'CWNC/cwnc.csv')['train']\n",
    "wikibias = load_dataset('csv',data_files = CS_DATA_PATH + 'WikiBias/wikibias.csv')['train']\n",
    "basil = load_dataset('csv',data_files = CS_DATA_PATH + 'BASIL/basil.csv')['train']\n",
    "nfnj = load_dataset('csv',data_files = CS_DATA_PATH + 'NFNJ/nfnj.csv')['train']\n",
    "ua_crisis = load_dataset('csv',data_files = CS_DATA_PATH + 'UA-crisis/ua-crisis.csv')['train']\n",
    "mpqa = load_dataset('csv',data_files = CS_DATA_PATH + 'MPQA/mpqa.csv')['train']\n",
    "subj = load_dataset('csv',data_files = CS_DATA_PATH + 'SUBJ/subj.csv')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "545a0519-d110-4925-a89f-87d5a565ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=BATCH_SIZE,  \n",
    "    logging_steps=50,\n",
    "    disable_tqdm = False,\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.1,\n",
    "    learning_rate=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8875afca-46d3-4a25-a790-544d03c10882",
   "metadata": {},
   "source": [
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019983b5-387f-437a-a258-2b96a962bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f088fc-eae8-41d7-bc7f-24562ac1ddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/horyctom/bias-detection-thesis/src/models/trained/all_balanced.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b07d396-ba1a-4bb7-a433-e3ec93457bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = concatenate_datasets([cw_hard,cwnc,wikibias,resample(basil),resample(nfnj),resample(ua_crisis),mpqa,subj]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa4f883f-1a02-4fed-b774-e7d2e8728643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de6733238e4d61a83f8753917164f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tok = preprocess_data(all_,tokenizer,'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e2522d0-51aa-4c58-ad6b-30b037c9e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_dataloader = DataLoader(all_tok, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "logits = torch.Tensor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3703801c-64e2-409c-9a1d-757da19ec5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1444/1444 [01:04<00:00, 22.52it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "for batch in tqdm(unlabelled_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = torch.cat((logits,F.softmax(outputs.logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ff1aabe-6b47-494f-9ee2-c318c41f3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_topk_indices = torch.topk(logits[:,0],k)[1]\n",
    "biased_topk_indices = torch.topk(logits[:,1],k)[1]\n",
    "indices = torch.cat((unbiased_topk_indices,biased_topk_indices)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf195f92-e0eb-4cf6-899b-033eb0a8fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25772, 20059, 41556,  ..., 15036,  7623, 12238])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "102f2f61-78dd-439a-adda-893933bb6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new augmentation and concat it\n",
    "masks = all_tok[indices]['attention_mask']\n",
    "input_ids = all_tok[indices]['input_ids']\n",
    "labels = [0]*len(unbiased_topk_indices) + [1]*len(biased_topk_indices)\n",
    "token_type_ids = all_tok[indices]['token_type_ids']\n",
    "to_add = Dataset.from_dict({'attention_mask':masks,'input_ids':input_ids,'label':labels,'token_type_ids':token_type_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fa5b6d4-5f3c-4447-a644-ddb8156d142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e78c852e301446b8b279e7a5036eecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_add = preprocess_data(subj,tokenizer,'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc7d2234-4731-4d2e-abf5-e8d683fb3475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73402be01e7e4bd8b0b1581e15e893d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subj_small = Dataset.from_dict(subj[:2500])\n",
    "to_add = preprocess_data(subj_small,tokenizer,'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da043db-53ef-4120-8a54-cdebd41c98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "babe_tok = preprocess_data(babe,tokenizer,'sentence')\n",
    "print(\"Running 10-fold CV on model: \",model_name,\"...\")\n",
    "for train_index, val_index in skfold.split(babe_tok['input_ids'],babe_tok['label']):\n",
    "\n",
    "    token_train = Dataset.from_dict(babe_tok[train_index])\n",
    "    token_valid = Dataset.from_dict(babe_tok[val_index])\n",
    "\n",
    "    token_train = concatenate_datasets([token_train,to_add])\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2);\n",
    "    model.to(device)\n",
    "    trainer = Trainer(model,training_args,train_dataset=token_train,data_collator=data_collator,tokenizer=tokenizer)\n",
    "    trainer.train()\n",
    "\n",
    "    #evaluation\n",
    "    eval_dataloader = DataLoader(token_valid, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "    scores.append(compute_metrics(model,device,eval_dataloader)['f1'])\n",
    "    print(scores[-1])\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee6040-787d-4425-bfd7-5280980904df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
