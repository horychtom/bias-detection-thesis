{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a6757e-e241-4c98-add8-77f8e14aa321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making imports convenient\n",
    "import sys\n",
    "import os\n",
    "PATH=os.getcwd().split('/notebooks')[0]\n",
    "sys.path.insert(1, PATH)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, Dataset,concatenate_datasets\n",
    "import transformers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding,AutoModelForSequenceClassification,AdamW,get_scheduler,TrainingArguments,\\\n",
    "                            Trainer,EarlyStoppingCallback\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from src.utils.myutils import *\n",
    "import logging\n",
    "logging.disable(logging.ERROR)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "model_name = 'ufal/robeczech-base'\n",
    "CONFIG_PATH = PATH + '/src/utils/config.yaml'\n",
    "MODELS_PATH = PATH + '/src/models/trained/'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "            output_dir = './',\n",
    "            num_train_epochs=3,\n",
    "            save_total_limit=2,\n",
    "            disable_tqdm=False,\n",
    "            per_device_train_batch_size=BATCH_SIZE,  \n",
    "            warmup_steps=0,\n",
    "            weight_decay=0.1,\n",
    "            logging_dir='./',\n",
    "            learning_rate=2e-5)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False,padding=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4702a23-751a-4352-b52c-0525eb35f93e",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e5a9c2-1555-4546-8af1-efabda538ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "babe = load_dataset('csv',data_files = PATH + '/data/CS/processed/BABE/train.csv')['train']\n",
    "cwnc = load_dataset('csv',data_files = PATH + '/data/CS/processed/CWNC/train.csv')['train']\n",
    "\n",
    "basil = load_dataset('csv',data_files = PATH + '/data/CS/raw/BASIL/basil.csv')['train']\n",
    "cw_hard = load_dataset('csv',data_files = PATH + '/data/CS/raw/CW-HARD/cw-hard.csv')['train']\n",
    "mpqa = load_dataset('csv',data_files = PATH + '/data/CS/raw/MPQA/mpqa.csv')['train']\n",
    "nfnj = load_dataset('csv',data_files = PATH + '/data/CS/raw/NFNJ/nfnj.csv')['train']\n",
    "subj = load_dataset('csv',data_files = PATH + '/data/CS/raw/SUBJ/subj.csv')['train']\n",
    "ua_crisis = load_dataset('csv',data_files = PATH + '/data/CS/raw/UA-crisis/ua-crisis.csv')['train']\n",
    "wikibias = load_dataset('csv',data_files = PATH + '/data/CS/raw/WikiBias/wikibias.csv')['train']\n",
    "\n",
    "datasets = [babe,cwnc,basil,cw_hard,mpqa,nfnj,subj,ua_crisis,wikibias]\n",
    "datasets_str = ['babe','cwnc','basil','cw_hard','mpqa','nfnj','subj','ua_crisis','wikibias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa149cb4-fcc5-4b18-b9da-8b50e8592ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babe\n",
      "cwnc\n",
      "basil\n",
      "cw_hard\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bdd5c3e3f64072a86cb74e466e6c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpqa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dc670e9b4748af956b3bce74324394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfnj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ae70509cd54a6b97977ad3b1b375ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dc7fbdfef94457a1345dd3be18a4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ua_crisis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2528edd02f804cffb309f86e4f609e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikibias\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2877e6fbcb40b2b7a044046d9f3d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = {}\n",
    "for i in range(len(datasets)):\n",
    "    print(datasets_str[i])\n",
    "    tokenized[datasets_str[i]] = preprocess_data(datasets[i],tokenizer,'sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b3ee7-eae3-4a0c-aed2-7997fbec5fda",
   "metadata": {},
   "source": [
    "## Eval Babe Baseline with seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a20138-f93e-4149-9ab6-8e5588227456",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/horyctom/venv/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py:44: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:135.)\n",
      "  return torch.tensor(value, **{**default_dtype, **self.torch_tensor_kwargs})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 00:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7869009980782344\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 00:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7694805194805194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 00:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7797558166795913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 00:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7861863037838367\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 00:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7698396935735565\n",
      "[0.7869009980782344, 0.7694805194805194, 0.7797558166795913, 0.7861863037838367, 0.7698396935735565]\n",
      "0.7784326663191476\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for train_index, val_index in skfold.split(tokenized['babe']['input_ids'],tokenized['babe']['label']):\n",
    "    token_train = Dataset.from_dict(tokenized['babe'][train_index])\n",
    "    token_valid = Dataset.from_dict(tokenized['babe'][val_index])\n",
    "\n",
    "    torch.cuda.manual_seed(12345)\n",
    "    torch.manual_seed(12345)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2);\n",
    "    model.to(device)\n",
    "    \n",
    "    trainer = Trainer(model,training_args,train_dataset=token_train,data_collator=data_collator,tokenizer=tokenizer)\n",
    "    trainer.train()\n",
    "\n",
    "    #evaluation\n",
    "    eval_dataloader = DataLoader(token_valid, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "    scores.append(compute_metrics(model,device,eval_dataloader)['f1'])\n",
    "    print(scores[-1])\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b190a2-157a-430d-ab0b-8185e9ab3842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
